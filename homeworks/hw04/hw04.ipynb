{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: Simulation, Sampling, and Bootstrapping\n",
    "\n",
    "## Due Thursday, February 20th at 11:59PM\n",
    "\n",
    "Welcome to Homework 4! This homework will cover:\n",
    "- Simulations (see [CIT 9.3-9.4](https://inferentialthinking.com/chapters/09/3/Simulation.html))\n",
    "- Sampling and Empirical Distributions (see [CIT 10-10.4](https://inferentialthinking.com/chapters/10/Sampling_and_Empirical_Distributions.html))\n",
    "- Bootstrapping and Confidence Intervals (see [CIT 13.2](https://inferentialthinking.com/chapters/13/2/Bootstrap.html) and [CIT 13.3](https://inferentialthinking.com/chapters/13/3/Confidence_Intervals.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Remember to start early and submit often. You are given six slip days throughout the quarter to extend deadlines. See the syllabus for more details. With the exception of using slip days, late work will not be accepted unless you have made special arrangements with your instructor.\n",
    "\n",
    "**Important**: For homeworks, the `otter` tests don't usually tell you that your answer is correct. More often, they help catch careless mistakes. It's up to you to ensure that your answer is correct. If you're not sure, ask someone (not for the answer, but for some guidance about your approach). These are great questions for office hours (the schedule can be found [here](https://dsc10.com/calendar)) or Ed. Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell, but do make sure to run it.\n",
    "import babypandas as bpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lucky Triton Lotto, Continued  üî± üé± üßú\n",
    "\n",
    "In the last homework, we calculated the probability of winning the grand prize (free housing) on a Lucky Triton Lotto lottery ticket, and found that it was quite low üò≠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "free_housing_chance = (1 / 29) * (1 / 28) * (1 / 27) * (1 / 26) * (1 / 25) * (1 / 12)\n",
    "free_housing_chance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, we'll approach the same question not using math, but using simulation. \n",
    "\n",
    "It's important to remember how this lottery works:\n",
    "\n",
    "- First, you pick five **different** numbers, one at a time, from 1 to 29, representing that according to [USNews](https://www.usnews.com/best-colleges/university-of-california-san-diego-1317), UCSD is ranked 29th in the nation for best universities to attend for 2024-2025.\n",
    "- Then, you separately pick a number from 1 to 12. This is because UCSD's Data Science program is ranked 12th in [USNews's](https://www.usnews.com/best-colleges/rankings/computer-science/data-analytics-science) best undergraduate Data Science programs list (though we think it's number one). Let's say you select 3.\n",
    "- The six numbers you have selected, or  **your numbers**, can be represented all together as (7, 12, 24, 15, 13, 3). This is a _sequence_ of six numbers ‚Äì **order matters**!\n",
    "\n",
    "The **winning numbers** are chosen by King Triton drawing five balls, one at a time, **without replacement**, from a pot of white balls numbered 1 to 29. Then, he draws a gold ball, the Tritonball, from a pot of gold balls numbered 1 to 12. Both pots are completely separate, hence the different ball colors. For example, maybe the winning numbers are (15, 9, 24, 23, 1, 3).\n",
    "\n",
    "We‚Äôll assume for this problem that in order to win the grand prize (free housing), all six of your numbers need to match the winning numbers and be in the **exact same order**. In other words, your entire sequence of numbers must be exactly the same as the sequence of winning numbers. However, if some numbers in your sequence match up with the corresponding number in the winning sequence, you will still win some Triton Cash. \n",
    "\n",
    "Suppose again that you select (7, 12, 24, 15, 13, 3) and the winning numbers are (15, 9, 24, 23, 1, 3). In this case, two of your numbers are considered to match two of the winning numbers. \n",
    "- Your numbers: (7, 12, **24**, 15, 13, **3**)\n",
    "- Winning numbers: (15, 9, **24**, 23, 1, **3**)\n",
    "\n",
    "You won't win free housing, but you will win some Triton Cash. Note that although both sequences include the number 15 within the first five numbers (representing a white ball), since they are in different positions, that's not considered a match.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1.** Implement a function called `simulate_one_ticket`. It should take no arguments, and it should return an array with 6 random numbers, simulating how the numbers are selected for a single Lucky Triton Lotto ticket. The first five numbers should all be randomly chosen without replacement, from 1 to 29. The last number should be between 1 and 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_one_ticket():\n",
    "    \"\"\"Simulate one Lucky Triton Lotto ticket.\"\"\"\n",
    "    ...\n",
    "simulate_one_ticket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.** It's draw day. You checked the winning numbers King Triton drew, which happened to be **(15, 9, 24, 23, 1, 3)**. Below, calculate how many matches there are between the winning numbers and a randomly generated ticket, and save the result in `num_matches`. Remember, order matters when counting matches!\n",
    "\n",
    "***Hint:*** You don't need a `for`-loop for this question. There is a one-line solution using `np.count_nonzero`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning = np.array([15, 9, 24, 23, 1, 3])\n",
    "simulated_ticket = simulate_one_ticket()\n",
    "num_matches = ...\n",
    "\n",
    "print(f\"The number of matches between the winning numbers {winning} and the simulated ticket {simulated_ticket} is {num_matches}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** You are disappointed because you bought a lottery ticket but you did not win free housing. To make yourself feel better, you write a simulation to remind yourself how unlikely it is to win the grand prize. \n",
    "\n",
    "Implement a simulation where you call the function `simulate_one_ticket` 100,000 times. In your 100,000 tickets, **how many times did you win the grand prize (free housing)?** Assign your answer to `count_free_housing`. (It would cost a fortune if you were to buy 100,000 tickets ‚Äì it's pretty nice to be able to simulate this experiment instead of doing it in real life!) \n",
    "\n",
    "***Hint:*** Start by writing a simulation where you only buy 10 tickets. Once you are sure you have that figured out, then ramp it up to 100,000 tickets. This is a good general practice for writing simulations: start small! It may take a little while (up to a minute) for Python to perform the calculations when you are buying 100,000 tickets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning = np.array([15, 9, 24, 23, 1, 3])\n",
    "count_free_housing = ...\n",
    "...\n",
    "count_free_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many times did you win free housing? Remember, the mathematical probability of winning free housing is quite low, on the order of $10^{-11}$. That's a lot lower than 1 in 100,000, which is $10^{-5}$.\n",
    "\n",
    "**Question 1.4.** As we've seen, you would need to be extremely lucky to win the grand prize. To encourage more students to buy Lucky Triton Lotto tickets despite the terrible odds, there are some additional prizes. Students can win Triton Cash if *some* of their numbers match the corresponding winning numbers, as described in the introduction. Again, simulate the act of buying 100,000 tickets, but this time find **the greatest number of matches achieved by any of your tickets**, and assign this number to `most_matches`. \n",
    "\n",
    "For example, if 90,000 of your tickets matched 1 winning number and 10,000 of your tickets matched 2 winning numbers, then you would set `most_matches` to 2. If 99,999 of your tickets matched 1 winning number and one of your tickets matched 4 winning numbers, you would set `most_matches` to 4. If you happened to win the grand prize on one of your tickets, you would set `most_matches` to 6. \n",
    "\n",
    "***Hint:*** There are several ways to approach this; one way involves storing the number of matches per ticket in an array and finding the largest number in that array. Another way involves keeping track of the maximum matches you've encountered so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning = np.array([15, 9, 24, 23, 1, 3])\n",
    "most_matches = ...\n",
    "...\n",
    "most_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5.** Suppose one Lucky Triton Lotto ticket costs $5.\n",
    "\n",
    "The Lucky Triton Lotto advertisement on Instagram promises you will never lose money because of the following generous prizes:\n",
    "\n",
    "- Win $10 with a 1-number match\n",
    "\n",
    "- Win $25 with a 2-number match\n",
    "\n",
    "- Win $100 with a 3-number match\n",
    "\n",
    "- Win $1,000 with a 4-number match\n",
    "\n",
    "- Win $5,000 with a 5-number match\n",
    "\n",
    "- Win $20,000 with a 6-number match (free housing!)\n",
    "\n",
    "If you had the money to buy 100,000 tickets, what would be your net winnings from buying these tickets? Since this is net winnings, this should account for the prizes you win and the cost of buying the tickets. Assign the amount to `net_winnings`. Note that a positive value means you won money overall, and a negative value means you lost money overall. Do you believe the advertisement's claims?\n",
    "\n",
    "The winning numbers are the same from the previous part: **(15, 9, 24, 23, 1, 3)**.\n",
    "\n",
    "***Hint:*** Again, there are a few ways you could approach this problem. One way involves generating another 100,000 random tickets and counting the amount earned per ticket, adding to a running total. Alternatively, if you created an array of the number of matches per ticket in Question 1.4, you could loop through that array. For practice, it's recommended that you try solving this problem multiple ways!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_winnings = ...\n",
    "...\n",
    "net_winnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Swimming with Sharks ü¶à\n",
    "\n",
    "In this question, we will use a [dataset](https://www.kaggle.com/datasets/ulrikthygepedersen/shark-tank-companies?resource=download) consisting of information about every pitch from the first 6 seasons of Shark Tank. \n",
    "\n",
    "<center><img src=\"./images/shark_tank.jpg\" alt=\"Shark Tank\" width=\"300\"></center>\n",
    "\n",
    "Shark Tank is a reality TV show where entrepreneurs pitch their business ideas to a panel of wealthy investors, called \"sharks,\" in hopes of securing funding. Each entrepreneur presents their product, business model, and financials, trying to convince the sharks that their company is worth investing in. You may have heard of products such as the Bombas Socks, Scrub Daddy sponges, and the Squatty Potty, all of which had their start on Shark Tank! Below we have provided a description of the information in the data:\n",
    "\n",
    "| **Column**            | **Description** |\n",
    "|---------------------|----------------|\n",
    "| `Episode` | The episode of the pitch|\n",
    "| `Season` | The season of the pitch |\n",
    "| `Deal` | Whether or not the company made a deal with one of the sharks |\n",
    "| `Category` | The category of the product |\n",
    "| `Asked For` | The amount of money requested by the entrepreneur |\n",
    "| `Valuation` | The amount of money the entrepreneur believes their business is worth |\n",
    "\n",
    "We'll use this data to get some practice with sampling. Run the cell below to load the data into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "shark_tank = bpd.read_csv('data/shark_tank.csv')\n",
    "shark_tank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've provided a function called `compute_statistics` that takes as input a DataFrame with two columns, `'Asked For'` and `'Valuation'`, and then:\n",
    "- draws a histogram of `'Asked For'`,\n",
    "- draws a histogram of `'Valuation'`, and\n",
    "- returns a two-element array containing the mean `'Asked For'` and mean `'Valuation'`.\n",
    "\n",
    "Run the cell below to define the `compute_statistics` function, and a helper function called `histograms`. Don't worry about how this code works, and please don't change anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell, just run it.\n",
    "def histograms(df):\n",
    "    askedfor = df.get('Asked For').values\n",
    "    valuation = df.get('Valuation').values\n",
    "    \n",
    "    plt.subplots(1, 2, figsize=(15, 4), dpi=100)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(askedfor, density=True, alpha=0.5, color='blue', ec='w', bins=np.arange(0, 3000000, 250000))\n",
    "    plt.title('Distribution of Asked For')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(valuation, density=True, alpha=0.5, color='blue', ec='w', bins=np.arange(0, 25000000, 2500000))\n",
    "    plt.title('Distribution of Valuation')\n",
    "    \n",
    "def compute_statistics(asked_and_valuation_data, draw=True):\n",
    "    if draw:\n",
    "        histograms(asked_and_valuation_data)\n",
    "    avg_asked = asked_and_valuation_data.get('Asked For').mean()\n",
    "    avg_valuation = asked_and_valuation_data.get('Valuation').mean()\n",
    "    avg_array = np.array([avg_asked, avg_valuation]) \n",
    "    return avg_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this `compute_statistics` function to show the distribution of `'Asked For'` and `'Valuation'` and compute their means, for any collection of pitches. \n",
    "\n",
    "Run the next cell to show these distributions and compute the means for all pitches. Notice that an array containing the mean `'Asked For'` and mean `'Valuation'` values is displayed before the histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_tank_stats = compute_statistics(shark_tank)\n",
    "shark_tank_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, imagine that instead of having access to the full *population* of Shark Tank picthes, we only have access to data on a smaller subset of pitches, or a *sample*.  For 495 pitches, it's not so unreasonable to expect to see all the data, but usually we aren't so lucky.  Instead, we often make *statistical inferences* about a large underlying population using a smaller sample.\n",
    "\n",
    "**Statistical inference** is the process of using data in a sample to _infer_ some characteristic about the population from which the sample was drawn. A common strategy for statistical inference is to estimate a parameter of the population by computing a corresponding statistic on a sample. This strategy sometimes works well and sometimes doesn't.  The degree to which it gives us useful answers depends on several factors.\n",
    "\n",
    "One very important factor in the utility of samples is how they were gathered. Let's look at some different sampling strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convenience sampling\n",
    "One sampling methodology, which is **generally a bad idea**, is to choose pitches which are somehow convenient to sample.  For example, you might choose pitches from a single season, or from only certain categories.  This is called *convenience sampling*.\n",
    "\n",
    "**Question 2.1.**  Suppose you only have access to data on the Shark Tank pitches for certain categories: `'Specialty Food'`, and `'Novelties'`. Assign `convenience_sample` to a subset of `shark_tank` that contains only the rows for pitches of these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convenience_sample = ...\n",
    "convenience_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** Assign `convenience_stats` to an array of the mean `'Asked For'` and mean `'Valuation'` of your convenience sample. Since they're computed on a sample, these are called sample means.\n",
    "\n",
    "***Hint:*** Use the function `compute_statistics`; it's okay if histograms are displayed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convenience_stats = ...\n",
    "convenience_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll compare the distribution of `'Valuation'` in our convenience sample to the distribution of `'Valuation'` for all the pitches in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell, do not change it!\n",
    "def compare_shots(first, second, first_title, second_title):\n",
    "    \"\"\"Compare the shots in two DataFrames.\"\"\"\n",
    "    bins = np.arange(0, 2800000, 200000)\n",
    "    \n",
    "    plt.subplots(1, 2, figsize=(15, 4), dpi=85)\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(first.get('Valuation'), bins=bins, density=True, ec='w', color='blue', alpha=0.5)\n",
    "    plt.title(f'Valuation ({first_title})')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(second.get('Valuation'), bins=bins, density=True, ec='w', color='blue', alpha=0.5)\n",
    "    plt.title(f'Valuation ({second_title})')\n",
    "\n",
    "compare_shots(shark_tank, convenience_sample, 'All Pitches', 'Convenience Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** From what you see in the histograms above, did the convenience sample give us an accurate picture of the valuation for the full population of Shark Tank pitches?  Why or why not?\n",
    "\n",
    "Assign either 1, 2, 3, or 4 to the variable `sampling_q3` below. \n",
    "1. Yes. The sample is large enough, so it is an accurate representation of the population.\n",
    "1. No. Convenience samples generally don't give us an accurate representation of the population.\n",
    "1. No. Normally convenience samples give us an accurate representation of the population, but we just got unlucky.\n",
    "1. No. Normally convenience samples give us an accurate representation of the population, but only if the sample size is large enough. Our convenience sample here was too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_q3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple random sampling\n",
    "A more principled approach is to sample uniformly at random from the pitches.  If we ensure that each pitch is selected at most once, this is a **random sample without replacement**, sometimes called a \"**simple random sample**\" or \"**SRS**\".  Imagine writing down each pitch on a card, putting the cards in a hat, and shuffling the hat.  To sample, pull out cards one by one and set them aside, stopping when the specified *sample size* is reached.\n",
    "\n",
    "We've produced two simple random samples of `shark_tank`: the variable `small_srs_data` contains a SRS of size 30, and the variable `large_srs_data` contains a SRS of size 260."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll run the same analyses on the small simple random sample, the large simple random sample, and the convenience sample. The subsequent code draws the histograms and computes the means for `'Asked For'` and `'Valuation'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell, but do run it.\n",
    "small_srs_data = bpd.read_csv('data/small_srs.csv')\n",
    "large_srs_data = bpd.read_csv('data/large_srs.csv')\n",
    "\n",
    "small_stats = compute_statistics(small_srs_data, draw=False);\n",
    "large_stats = compute_statistics(large_srs_data, draw=False);\n",
    "convenience_stats = compute_statistics(convenience_sample, draw=False);\n",
    "\n",
    "print('Full data stats:                 ', shark_tank_stats)\n",
    "print('Small SRS stats:                 ', small_stats)\n",
    "print('Large SRS stats:                 ', large_stats)\n",
    "print('Convenience sample stats:        ', convenience_stats)\n",
    "\n",
    "color_dict = {\n",
    "    'small SRS': 'blue',\n",
    "    'large SRS': 'green',\n",
    "    'convenience sample': 'orange'\n",
    "}\n",
    "\n",
    "plt.subplots(3, 2, figsize=(15, 15), dpi=100)\n",
    "i = 1\n",
    "\n",
    "for df, name in zip([small_srs_data, large_srs_data, convenience_sample], color_dict.keys()):\n",
    "    plt.subplot(3, 2, i)\n",
    "    i += 2\n",
    "    plt.hist(df.get('Asked For'), density=True, alpha=0.5, color=color_dict[name], ec='w', bins=np.arange(0, 3000000, 250000))\n",
    "    plt.title(f'Asked For ({name})');\n",
    "\n",
    "i = 2\n",
    "for df, name in zip([small_srs_data, large_srs_data, convenience_sample], color_dict.keys()):\n",
    "    plt.subplot(3, 2, i)\n",
    "    i += 2\n",
    "    plt.hist(df.get('Valuation'), density=True, alpha=0.5, color=color_dict[name], ec='w', bins=np.arange(0, 25000000, 2500000))\n",
    "    plt.title(f'Valuation ({name})');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing simple random samples\n",
    "Often it's useful to take random samples even when we have a larger dataset available.  One reason is that doing so can help us understand how inaccurate other samples are.\n",
    "\n",
    "As we saw in [Lecture 13](https://dsc10.com/resources/lectures/lec13/lec13.html#Sampling-rows-from-a-DataFrame), DataFrames have a `.sample` method for producing simple random samples.  Note that its default is to sample **without** replacement, which aligns with how simple random samples are drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** Produce a simple random sample of size 30 from `shark_tank`. Store an array containing the mean `'Asked For'` and mean `'Valuation'` of your SRS in `my_small_stats`. Again, it's fine if histograms are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_small_stats = ...\n",
    "my_small_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell above many times, to collect new samples and compute their sample means.\n",
    "\n",
    "<br>\n",
    "\n",
    "Now, recall, `small_stats` is an array containing the mean `'Asked For'` and mean `'Valuation'` for the one small SRS that we provided you with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following two-fold question:\n",
    "- Are the values in `my_small_stats` (the mean `'Asked For'` and `'Valuation'` for **your** small SRS) similar to the values in `small_stats` (the mean `'Asked For'` and `'Valuation'` for the small SRS **we provided you with**)? \n",
    "- Each time you collect a new sample ‚Äì i.e. each time you re-run the cell where `my_small_stats` is defined ‚Äì do the values in `my_small_stats` change a lot?\n",
    "\n",
    "Assign either 1, 2, 3, or 4 to the variable `sampling_q4` below.\n",
    "1. The values in `my_small_stats` are identical to the values in `small_stats`, and change a bit each time a new sample is collected.\n",
    "1. The values in `my_small_stats` are identical to the values in `small_stats`, and don't change at all each time a new sample is collected.\n",
    "1. The values in `my_small_stats` are slightly different from the values in `small_stats`, and change a bit each time a new sample is collected.\n",
    "1. The values in `my_small_stats` are very different from the values in `small_stats`, and don't change at all each time a new sample is collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_q4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5.** Similarly, create a simple random sample of size 260 from `shark_tank` and store an array of the sample's mean `'Asked For'` and mean `'Valuation'` in `my_large_stats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_large_stats = ...\n",
    "my_large_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell in which `my_large_stats` is defined many times. Do the histograms and  mean statistics (mean `'Asked For'` and mean `'Valuation'`) seem to change more or less across samples of size 260 than across samples of size 30?\n",
    "\n",
    "Assign either 1, 2, or 3 to the variable `sampling_q5` below. \n",
    "\n",
    "1. The statistics change *less* across samples of size 260 than across samples of size 30.\n",
    "1. The statistics change an *equal amount* across samples of size 260 and across samples of size 30.\n",
    "1. The statistics change *more* across samples of size 260 than across samples of size 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_q5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Milk Tea, Yippee! ü•õüçµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are planning to open a milk tea shop in La Jolla! To get a sense of the local residents' milk tea preferences, you survey 200 randomly selected La Jolla residents and ask which type of tea they prefer the most among six options ‚Äì `'jasmine'`, `'oolong'`, `'black'`, `'golden'`, `'matcha'`, `'Thai'`. \n",
    "\n",
    "<center><img src=\"images/tea.png\" width=70%></center>\n",
    "\n",
    "Run the next cell to load in the results of the survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = bpd.read_csv('data/tea.csv')\n",
    "survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you're truly interested in, though, is the proportion of *all La Jolla residents* that prefer each type of tea. These are *population parameters* (plural, because there are six proportions).\n",
    "\n",
    "Your friends tell you that matcha tea is popular (it doesn't just taste like grass!) and that your shop should focus on matcha tea-based creations. To make an informed decision, you decide to look at your survey data to determine the proportion of La Jolla residents that prefer `'matcha'` tea over all other types of teas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.** Start by calculating the proportion of residents in your sample who prefer `'matcha'` tea. Assign this value to `matcha_proportion`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcha_proportion = ...\n",
    "matcha_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're done... or are you? You have a single estimate for the true proportion of residents who prefer `'matcha'` tea. However, you don't know how close that estimate is, or how much it could have varied if you'd had a different sample. In other words, you have an estimate, but no understanding of how close that estimate is to the true proportion of all local residents who prefer `'matcha'` tea.\n",
    "\n",
    "This is where the idea of resampling via **[bootstrapping](https://inferentialthinking.com/chapters/13/2/Bootstrap.html)** comes in. Assuming that our sample resembles the population fairly well, we can resample from our original sample to produce more samples. From each of these resamples, we can produce another estimate for the true proportion of residents who prefer `'matcha'` tea, which gives us a distribution of sample proportions that describes how the estimate might vary given different samples. We can then use this distribution to understand the **variability** in the estimated proportion of residents who prefer `'matcha'` tea.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2.** Now, let's use bootstrapping to get a sense of the distribution of the sample proportion. Complete the following code to produce 1,000 bootstrapped estimates for the proportion of residents who prefer `'matcha'` tea. Store your 1,000 estimates in an array named `boot_matcha_proportions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boot_matcha_proportions = ...\n",
    "for i in np.arange(1000):\n",
    "    resample = ...\n",
    "    resample_proportion = ...\n",
    "    boot_matcha_proportions = ...\n",
    "boot_matcha_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3.** Using the array `boot_matcha_proportions`, compute an approximate **95%** confidence interval for the true proportion of residents who prefer `'matcha'` tea.  Compute the lower and upper ends of the interval, named `matcha_lower_bound` and `matcha_upper_bound`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcha_lower_bound = ...\n",
    "matcha_upper_bound = ...\n",
    "\n",
    "# Print the confidence interval:\n",
    "print(\"Bootstrapped 95% confidence interval for the true proportion of residents who prefer matcha tea in the population:\\n[{:f}, {:f}]\".format(matcha_lower_bound, matcha_upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4.**\n",
    "Is it true that 95% of the population lies in the range `matcha_lower_bound` to `matcha_upper_bound`? Assign the variable `q3_4` to either `True` or `False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_4 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5.**\n",
    "Is it true that the proportion of La Jolla residents who prefer `'matcha'` tea over the other teas is a random quantity with approximately a 95% chance of falling between `matcha_lower_bound` and `matcha_upper_bound`? Assign the variable `q3_5` to either `True` or `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_5 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6.**\n",
    "Suppose we were somehow able to produce 2,000 new samples, each one a uniform random sample of 200 La Jolla residents taken directly from the population. For each of those 2,000 new samples, we create a 95% confidence interval for the proportion of residents who prefer `'matcha'` tea. Roughly how many of those 2,000 intervals should we expect to actually contain the true proportion of the population? Assign your answer to the variable `how_many` below. It should be of type `int`, representing the *number* of intervals, not the proportion or percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_many = ...\n",
    "how_many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7.** We also created 90%, 96%, and 99% confidence intervals from one sample (shown below), but forgot to label which confidence intervals were which! Match the interval to the percent of confidence the interval represents and assign your choices (either 1, 2, or 3) to variables `ci_90`, `ci_96`, and `ci_99`, corresponding to the 90%, 96%, and 99% confidence intervals respectively.\n",
    "\n",
    "**Hint**: Drawing the confidence intervals out on paper might help you visualize them better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $[0.135, 0.25]$\n",
    "\n",
    "2. $[0.145, 0.24]$\n",
    "\n",
    "3. $[0.12,  0.26]$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_90 = ...\n",
    "ci_96 = ...\n",
    "ci_99 = ...\n",
    "ci_90, ci_96, ci_99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.8.** Based on the results in `survey`, it seems that `'jasmine'` tea is more popular than `'matcha'` tea among residents. We would like to construct a range of likely values ‚Äì that is, a confidence interval ‚Äì for the difference in popularity, which we define as:\n",
    "\n",
    "$$\\text{(Proportion of residents who prefer jasmine tea)} - \\text{(Proportion of residents who prefer matcha tea)}$$\n",
    "\n",
    "Create a function, `differences_in_resamples`, that creates **1000 bootstrapped resamples of the original survey data** in the `survey` DataFrame, computes the difference in proportions for each resample, and returns an array of these differences. \n",
    "\n",
    "Then, call your function and store its output in an array called `boot_differences`.\n",
    "\n",
    "Finally, plot a density histogram of the estimates in `boot_differences`.\n",
    "\n",
    "***Hints:*** \n",
    "- Use your code from Question 3.2 as a starting point.\n",
    "- To plot your histogram, you'll first need to create a DataFrame with one column, whose entries are the values in `boot_differences`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student",
    "manual_problem_id": "election_2"
   },
   "outputs": [],
   "source": [
    "def differences_in_resamples():\n",
    "    ...\n",
    "\n",
    "boot_differences = ...\n",
    "\n",
    "# Plot a histogram of boot_differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.9.** Compute an approximate 95% confidence interval for the difference in proportions. Assign the lower and upper bounds of the interval to `diff_lower_bound` and `diff_upper_bound`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_lower_bound = ...\n",
    "diff_upper_bound = ...\n",
    "\n",
    "# Print the confidence interval:\n",
    "print(\"Bootstrapped 95% confidence interval for the difference in popularity between jasmine tea and matcha tea:\\n[{:f}, {:f}]\".format(diff_lower_bound, diff_upper_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.10.** In this question, you computed two 95% confidence intervals:\n",
    "- In Question 3.3, you found a 95% confidence interval for the proportion of residents who prefer `'matcha'` tea among the six tea options. Let's call this the \"matcha CI.\"\n",
    "- In Question 3.9, you found a 95% confidence interval for the difference between the proportion of residents who prefer `'jasmine'` tea and the proportion of residents who prefer `'matcha'` tea. Let's call this the \"difference CI.\" \n",
    "\n",
    "Choose how to best fill in the blanks to describe the widths of these two confidence intervals. Set `q3_10` to either 1, 2, 3, or 4.\n",
    "\n",
    ">The matcha CI is ________________________ than the difference CI because we have a ________________________ for a single unknown parameter than the difference between two unknown parameters.\n",
    "\n",
    "1. wider; more accurate guess\n",
    "1. narrower; more accurate guess\n",
    "1. wider; less accurate guess\n",
    "1. narrower; less accurate guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_10 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. BLACKPINK World Tourüñ§üíó\n",
    "\n",
    "On February 5, 2025, YG Entertainment announced that the K-Pop girl group, BLACKPINK (Î∏îÎûôÌïëÌÅ¨), will be going on a [world tour](https://www.elle.com/culture/music/a63676009/how-to-get-tickets-to-blackpink-2025-world-tour/) later this year. Fans were happy but surprised to hear the news as the group has not released any music together since 2022. Furthermore, all the artists in the group have been focusing on their solo careers, so it did not seem likely they would be going on a concert tour anytime soon. The tour dates have not been announced yet, but based on the their previous tours, they will likely perform at these 4 cities in Asia:\n",
    "\n",
    "- Seoul, South Korea\n",
    "- Tokyo, Japan\n",
    "- Bangkok, Thailand\n",
    "- Singapore, Singapore\n",
    "\n",
    "\n",
    "You and your friends are planning a trip to Asia to see BLACKPINK. Since you have a limited budget and will already spend a lot of money on the concert tickets, you want to stay in the city which has the cheapest hotels. You gathered hotel data from [Expedia](https://www.expedia.com/) for the four cities above. The `hotels` DataFrame contains a **sample** of all the hotels in the four cities above. Each row corresponds to a particular hotel, and the columns give us information about the `'Hotel Name'`, the `'City'`, the `'Price'` in USD for one night, and the `'Customer Rating'` from 1-10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels = bpd.read_csv('data/hotels.csv')\n",
    "hotels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1.** Let's start by determining the mean hotel price for each city. Create a DataFrame called `city_means`, indexed by `'City'`, with one column called `'Price'` that contains the mean hotel price for that city. Sort `city_means` in descending order of `'Price'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "city_means = ...\n",
    "city_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2.** Based on the data we have, Singapore on average has the most expensive hotels. However, our data is only a sample of all the hotels in the 4 cities, and the mean hotel price we computed for Singapore is only a sample statistic, not a population parameter. \n",
    "\n",
    "Produce 1,000 bootstrapped estimates for the mean price of **all** hotels in Singapore. Store the estimates in the `sg_hotel_means` array. Then, use the `sg_hotel_means` array to calculate an approximate **99% confidence interval** for the true mean price of all hotels in Singapore. Assign the endpoints of your interval to `lower_bound` and `upper_bound`.\n",
    "\n",
    "***Hint:*** Make sure to query **before** resampling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_hotel_means = ...\n",
    "\n",
    "\n",
    "lower_bound = ...\n",
    "upper_bound = ...\n",
    "\n",
    "# Display the estimates in a histogram.\n",
    "bpd.DataFrame().assign(Estimated_Average_Price=sg_hotel_means).plot(kind='hist', density=True, ec='w', figsize=(10, 5), title=\"Singapore\");\n",
    "plt.plot([lower_bound, upper_bound], [0, 0], color='gold', linewidth=10, label='99% confidence interval');\n",
    "\n",
    "# Don't change what's below (though you will need to copy and change it in 4.3).\n",
    "city_name = 'Singapore'\n",
    "f'A 99% confidence interval for the average hotel price in {city_name} is [{lower_bound}, {upper_bound}].'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3.** Now we want to create a similar histogram for the other 3 cities. Instead of copying our code from Question 4.2 and changing it to work for each city, let's write a more general function that works for _any_ city we choose. \n",
    "\n",
    "Create a function called `city_and_hist`, which takes in a city name as a string, and:\n",
    "1. **Plots the histogram** of 1,000 bootstrapped estimates for the city's mean hotel price.\n",
    "2. **Returns** a string describing the approximate 99% confidence interval for the city's mean hotel price, formatted in the same way as the string displayed for Singapore in Question 4.2.\n",
    "\n",
    "***Notes:*** \n",
    "- Make sure your function both plots a histogram and **returns** a string. For example, `city_and_hist('Tokyo')` should return a string that starts with `'A 99% confidence interval for the average hotel price in ... is'` where ... is the city name.\n",
    "- The string displayed at the end of Question 4.2. was created using a feature of Python called f-strings. You'll need to copy and change that f-string expression. Read [this article](https://realpython.com/python-f-strings/#simple-syntax) for more details about f-strings if you're interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def city_and_hist(city_name):\n",
    "    ...\n",
    "    \n",
    "# Example calls to the function. Don't change the lines below.\n",
    "tokyo_string = city_and_hist('Tokyo')\n",
    "print(tokyo_string)\n",
    "seoul_string = city_and_hist('Seoul')\n",
    "print(seoul_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish Line: Almost there, but make sure to follow the steps below to submit! üèÅ\n",
    "\n",
    "**_Citations:_** Did you use any generative artificial intelligence tools to assist you on this assignment? If so, please state, for each tool you used, the name of the tool (ex. ChatGPT) and the problem(s) in this assignment where you used the tool for help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">\n",
    "\n",
    "Please cite tools here.\n",
    "\n",
    "<hr style=\"color:Maroon;background-color:Maroon;border:0 none; height: 3px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit your assignment:\n",
    "\n",
    "1. Select `Kernel -> Restart & Run All` to ensure that you have executed all cells, including the test cells.\n",
    "2. Read through the notebook to make sure everything is fine and all tests passed.\n",
    "3. Run the cell below to run all tests, and make sure that they all pass.\n",
    "4. Download your notebook using `File -> Download as -> Notebook (.ipynb)`, then upload your notebook to Gradescope.\n",
    "5. Stick around while the Gradescope autograder grades your work. Make sure you see that all tests have passed on Gradescope.\n",
    "6. Check that you have a confirmation email from Gradescope and save it as proof of your submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
